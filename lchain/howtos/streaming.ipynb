{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to stream runnables](https://python.langchain.com/docs/how_to/streaming/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLMs and Chat Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| color| of| the| sky| can| vary| depending| on| several| factors| such| as| time| of| day|,| weather| conditions|,| and| atmospheric| particles|.| Generally|,| during| a| clear| day|,| the| sky| appears| blue| due| to| the| scattering| of| sunlight| by| the| Earth's| atmosphere|.| This| scattering| causes| shorter| wavelengths| of| light| (|blue|)| to| be| scattered| more| than| longer| wavelengths| (|red|).| During| sunrise| and| sunset|,| the| sky| can| take| on| hues| of| orange|,| pink|,| and| red| due| to| the| angle| of| the| sun| and| the| increased| distance| the| light| travels| through| the| atmosphere|.| On| cloudy| days|,| the| sky| may| appear| gray| or| white|.||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for chunk in model.stream(\"what color is the sky?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| color| of| the| sky| typically| appears| blue| during| the| day| due| to| the| scattering| of| sunlight| by| the| Earth's| atmosphere|.| This| scattering| causes| shorter| blue| wavelengths| of| light| to| be| more| prominent|.| However|,| the| sky| can| change| colors| depending| on| the| time| of| day|,| weather| conditions|,| and| other| factors|.| For| example|,| it| can| appear| gray| on| cloudy| days|,| orange| or| pink| during| sunrise| and| sunset|,| and| even| black| at| night| when| the| sun| is| down|.||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in model.astream(\"what color is the sky?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-0b269c60-e284-4e76-abe8-56b6ae4f042f')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The color of the', additional_kwargs={}, response_metadata={}, id='run-0b269c60-e284-4e76-abe8-56b6ae4f042f')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0] + chunks[1] + chunks[2] + chunks[3] + chunks[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Why| did| the| par|rot| wear| a| rain|coat|?\n",
      "\n",
      "|Because| it| wanted| to| be| a| poly|-uns|aturated|!||"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"parrot\"}):\n",
    "    print(chunk, end=\"|\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with Input Streams**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要讲对于像json这样的数据格式，该如何进行stream处理。\n",
    "\n",
    "langchain 里提到：the parser needs to operate on the input stream, and attempt to \"auto-complete\" the partial json into a valid state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 652}]}\n",
      "{'countries': [{'name': 'France', 'population': 652735}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 467547}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126476}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126476461}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    print(text, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any steps in the chain that operate on finalized inputs rather than on input streams can break streaming functionality via stream or astream.\n",
    "\n",
    "也就是说中间的组件必须具备处理 input stream 的能力，否则就会打断 stream。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# A function that operates on finalized inputs\n",
    "# rather than on an input_stream\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以后续给了一个修正的例子：\n",
    "\n",
    "A generator function (a function that uses yield) allows writing code that operates on input streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<async_generator object tee_peer at 0x11d817be0>\n",
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "France|{'countries': [{'name': 'France', 'population': 652}]}\n",
      "{'countries': [{'name': 'France', 'population': 652735}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain'}]}\n",
      "Spain|{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 467547}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan'}]}\n",
      "Japan|{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126476}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126476461}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 大模型里提到入参 input_stream 是一个异步迭代器\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "    \"\"\"A function that operates on input streams.\"\"\"\n",
    "\n",
    "    print(input_stream)\n",
    "\n",
    "    country_names_so_far = set()\n",
    "\n",
    "    async for input in input_stream:\n",
    "\n",
    "        print(input)\n",
    "        \n",
    "        if not isinstance(input, dict):\n",
    "            continue\n",
    "\n",
    "        if \"countries\" not in input:\n",
    "            continue\n",
    "\n",
    "        countries = input[\"countries\"]\n",
    "\n",
    "        if not isinstance(countries, list):\n",
    "            continue\n",
    "\n",
    "        for country in countries:\n",
    "            name = country.get(\"name\")\n",
    "            if not name:\n",
    "                continue\n",
    "            if name not in country_names_so_far:\n",
    "                # 注意 yield 的用法\n",
    "                yield name\n",
    "                country_names_so_far.add(name)\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-streaming components**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些组件不支持 streaming："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='2ea5d1d7-e339-4fa7-837a-0418fde826b1', metadata={}, page_content='harrison worked at kensho'),\n",
       "  Document(id='52b39def-80ae-4644-b5a5-6360074727b9', metadata={}, page_content='harrison likes spicy food')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\", \"harrison likes spicy food\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chunks = [chunk for chunk in retriever.stream(\"where did harrison work?\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但如果chain中既有non-streaming组件也有streaming组件，很多情况下也是支持stream输出的，在最后一个non-streaming组件之后再stream输出部分output："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|H|arrison| worked| at| Kens|ho|.| Kens|ho| is| a| cutting|-edge| tech| company| known| for| its| innovative| approach| to| data| analytics|.| The| team| at| Kens|ho| enjoys| a| lively| atmosphere| where| creativity| thrives| and| collaboration| is| encouraged|.| Employees| often| gather| for| brainstorming| sessions| that| frequently| result| in| groundbreaking| ideas| and| solutions|.||"
     ]
    }
   ],
   "source": [
    "for chunk in retrieval_chain.stream(\n",
    "    \"Where did harrison work? \" \"Write 3 made up sentences about this place.\"\n",
    "):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Stream Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 astream_events 有几点建议：\n",
    "\n",
    "* Use async throughout the code to the extent possible (e.g., async tools etc)\n",
    "\n",
    "* Propagate callbacks if defining custom functions / runnables\n",
    "\n",
    "* Whenever using runnables without LCEL, make sure to call .astream() on LLMs rather than .ainvoke to force the LLM to stream tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "供参考的 events，见：https://python.langchain.com/docs/how_to/streaming/#event-reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chat Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "async for event in model.astream_events(\"hello\"):\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chat_model_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content='Hello', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content=' How', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content=' assist', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content=' today', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_end',\n",
       "  'data': {'output': AIMessageChunk(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}, id='run-0cc274c4-0ed8-488d-b86a-e2c58b358eec')},\n",
       "  'run_id': '0cc274c4-0ed8-488d-b86a-e2c58b358eec',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models\n",
    "\n",
    "events = [\n",
    "    event\n",
    "    async for event in chain.astream_events(\n",
    "        \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "        'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "        \"Each country should have the key `name` and `population`\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chain_start',\n",
       "  'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'},\n",
       "  'name': 'RunnableSequence',\n",
       "  'tags': [],\n",
       "  'run_id': '801abc9f-55d2-4c6a-bd8b-75e1a7327a3e',\n",
       "  'metadata': {},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_start',\n",
       "  'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`', additional_kwargs={}, response_metadata={})]]}},\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'run_id': '31591450-70ac-47e8-bf32-e08cb963eca1',\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'parent_ids': ['801abc9f-55d2-4c6a-bd8b-75e1a7327a3e']},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-31591450-70ac-47e8-bf32-e08cb963eca1')},\n",
       "  'run_id': '31591450-70ac-47e8-bf32-e08cb963eca1',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'parent_ids': ['801abc9f-55d2-4c6a-bd8b-75e1a7327a3e']}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chat_model_end',\n",
       "  'data': {'output': AIMessageChunk(content='Here is the requested information in JSON format:\\n\\n```json\\n{\\n  \"countries\": [\\n    {\\n      \"name\": \"France\",\\n      \"population\": 65273511\\n    },\\n    {\\n      \"name\": \"Spain\",\\n      \"population\": 46754778\\n    },\\n    {\\n      \"name\": \"Japan\",\\n      \"population\": 126476461\\n    }\\n  ]\\n}\\n```\\n\\nNote: The population figures are estimates as of 2023 and may vary.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}, id='run-31591450-70ac-47e8-bf32-e08cb963eca1'),\n",
       "   'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`', additional_kwargs={}, response_metadata={})]]}},\n",
       "  'run_id': '31591450-70ac-47e8-bf32-e08cb963eca1',\n",
       "  'name': 'ChatOpenAI',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'metadata': {'ls_provider': 'openai',\n",
       "   'ls_model_name': 'gpt-4o-mini',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': None},\n",
       "  'parent_ids': ['801abc9f-55d2-4c6a-bd8b-75e1a7327a3e']},\n",
       " {'event': 'on_parser_end',\n",
       "  'data': {'output': {'countries': [{'name': 'France', 'population': 65273511},\n",
       "     {'name': 'Spain', 'population': 46754778},\n",
       "     {'name': 'Japan', 'population': 126476461}]},\n",
       "   'input': AIMessageChunk(content='Here is the requested information in JSON format:\\n\\n```json\\n{\\n  \"countries\": [\\n    {\\n      \"name\": \"France\",\\n      \"population\": 65273511\\n    },\\n    {\\n      \"name\": \"Spain\",\\n      \"population\": 46754778\\n    },\\n    {\\n      \"name\": \"Japan\",\\n      \"population\": 126476461\\n    }\\n  ]\\n}\\n```\\n\\nNote: The population figures are estimates as of 2023 and may vary.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}, id='run-31591450-70ac-47e8-bf32-e08cb963eca1')},\n",
       "  'run_id': 'f35590b3-bcb2-4bd3-b300-a3e5e5f9ba1b',\n",
       "  'name': 'JsonOutputParser',\n",
       "  'tags': ['seq:step:2'],\n",
       "  'metadata': {},\n",
       "  'parent_ids': ['801abc9f-55d2-4c6a-bd8b-75e1a7327a3e']},\n",
       " {'event': 'on_chain_end',\n",
       "  'data': {'output': {'countries': [{'name': 'France', 'population': 65273511},\n",
       "     {'name': 'Spain', 'population': 46754778},\n",
       "     {'name': 'Japan', 'population': 126476461}]}},\n",
       "  'run_id': '801abc9f-55d2-4c6a-bd8b-75e1a7327a3e',\n",
       "  'name': 'RunnableSequence',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取出 model 和 parser 的events，忽略 start、end 以及 chain 相关的events："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: 'Here'\n",
      "Chat model chunk: ' is'\n",
      "Chat model chunk: ' the'\n",
      "Chat model chunk: ' requested'\n",
      "Chat model chunk: ' data'\n",
      "Chat model chunk: ' in'\n",
      "Chat model chunk: ' JSON'\n",
      "Chat model chunk: ' format'\n",
      "Chat model chunk: ':\\n\\n'\n",
      "Chat model chunk: '```'\n",
      "Chat model chunk: 'json'\n",
      "Chat model chunk: '\\n'\n",
      "Chat model chunk: '{\\n'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: ' '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'countries'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' [\\n'\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '   '\n",
      "Chat model chunk: ' {\\n'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: '     '\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # Truncate the output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering Events**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以过滤 events，或者根据 name，或者根据 tags，或者根据 type。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据 name："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_parser_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'my_parser', 'tags': ['seq:step:2'], 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'metadata': {}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': []}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': ''}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France'}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 652}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 652735}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 65273511}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 65273511}, {}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "{'event': 'on_parser_stream', 'run_id': 'a8619289-ff01-46d7-9cc6-5f9b30cfcfc6', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 65273511}, {'name': ''}]}}, 'parent_ids': ['46b9bae7-7f8e-4e5a-9100-c4d23118c162']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    include_names=[\"my_parser\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据 type："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'model', 'tags': ['seq:step:1'], 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' requested', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' information', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' JSON', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' format', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9a4c5daa-bcde-40cf-92a6-e8abbfb3d256')}, 'run_id': '9a4c5daa-bcde-40cf-92a6-e8abbfb3d256', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['e2c14543-d794-4194-96ac-bb6f5d4ebda7']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "    include_types=[\"chat_model\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By Tags**\n",
    "\n",
    "有风险提示：\n",
    "\n",
    "Tags are inherited by child components of a given runnable.\n",
    "\n",
    "If you're using tags to filter, make sure that this is what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'RunnableSequence', 'tags': ['my_chain'], 'run_id': '9983290a-d740-4c06-a7e9-07a30acfa68f', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`', additional_kwargs={}, response_metadata={})]]}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_parser_start', 'data': {}, 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'run_id': '9350d555-56fe-46a4-843f-9ea5e8339ce9', 'metadata': {}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' requested', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' JSON', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' format', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-f458ebee-71cf-4fc3-b37e-eb97a281e964')}, 'run_id': 'f458ebee-71cf-4fc3-b37e-eb97a281e964', 'name': 'ChatOpenAI', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': None}, 'parent_ids': ['9983290a-d740-4c06-a7e9-07a30acfa68f']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = (model | JsonOutputParser()).with_config({\"tags\": [\"my_chain\"]})\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "    include_tags=[\"my_chain\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-streaming components**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然在使用astream时，此类组件可能会中断最终输出的流，但astream_events仍将从支持流的中间步骤生成流事件！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that does not support streaming.\n",
    "# It operates on the finalizes inputs rather than\n",
    "# operating on the input stream.\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser() | _extract_country_names\n",
    ")  # This parser only works with OpenAI right now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这个例子验证 astream 不能很好的工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    print(chunk, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后验证 astream_events 仍然在 model 和 parser 阶段可见："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: '```'\n",
      "Chat model chunk: 'json'\n",
      "Chat model chunk: '\\n'\n",
      "Chat model chunk: '{\\n'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: ' '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'countries'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' [\\n'\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '   '\n",
      "Chat model chunk: ' {\\n'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: '     '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'name'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' \"'\n",
      "Parser chunk: {'countries': [{'name': ''}]}\n",
      "Chat model chunk: 'France'\n",
      "Parser chunk: {'countries': [{'name': 'France'}]}\n",
      "Chat model chunk: '\",\\n'\n",
      "Chat model chunk: '     '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'population'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # Truncate the output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propagating Callbacks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【caution】\n",
    "\n",
    "If you're using invoking runnables inside your tools, you need to propagate callbacks to the runnable; otherwise, no stream events will be generated.\n",
    "\n",
    "【note】\n",
    "\n",
    "When using RunnableLambdas or @chain decorator, callbacks are propagated automatically behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面举了两个例子：第一个是 bad case，第二个是 good case。但是我真没看出有啥区别！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'bad_tool', 'tags': [], 'run_id': '520f6fb5-169f-4e7f-b22a-4c1444263d3a', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': '41517c00-d353-474b-876d-3eb0f7fa36e0', 'metadata': {}, 'parent_ids': ['520f6fb5-169f-4e7f-b22a-4c1444263d3a']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': '41517c00-d353-474b-876d-3eb0f7fa36e0', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['520f6fb5-169f-4e7f-b22a-4c1444263d3a']}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': '520f6fb5-169f-4e7f-b22a-4c1444263d3a', 'name': 'bad_tool', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "def reverse_word(word: str):\n",
    "    return word[::-1]\n",
    "\n",
    "\n",
    "reverse_word = RunnableLambda(reverse_word)\n",
    "\n",
    "\n",
    "@tool\n",
    "def bad_tool(word: str):\n",
    "    \"\"\"Custom tool that doesn't propagate callbacks.\"\"\"\n",
    "    return reverse_word.invoke(word)\n",
    "\n",
    "\n",
    "async for event in bad_tool.astream_events(\"hello\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'correct_tool', 'tags': [], 'run_id': '9e0cef51-a5b4-4c14-99fb-38c89659d393', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': 'fcfe5b2c-f234-4c00-90ae-8d812f6ca637', 'metadata': {}, 'parent_ids': ['9e0cef51-a5b4-4c14-99fb-38c89659d393']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': 'fcfe5b2c-f234-4c00-90ae-8d812f6ca637', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['9e0cef51-a5b4-4c14-99fb-38c89659d393']}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': '9e0cef51-a5b4-4c14-99fb-38c89659d393', 'name': 'correct_tool', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def correct_tool(word: str, callbacks):\n",
    "    \"\"\"A tool that correctly propagates callbacks.\"\"\"\n",
    "    return reverse_word.invoke(word, {\"callbacks\": callbacks})\n",
    "\n",
    "\n",
    "async for event in correct_tool.astream_events(\"hello\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后下面两个例子，列举了使用 Lambdas or @chains 的情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '45e5abb1-31d2-45a4-8ba2-564a9b4f0c89', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_word', 'tags': [], 'run_id': '83d1d739-6bfb-4239-8659-4a6c53ba765c', 'metadata': {}, 'parent_ids': ['45e5abb1-31d2-45a4-8ba2-564a9b4f0c89']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '4321', 'input': '1234'}, 'run_id': '83d1d739-6bfb-4239-8659-4a6c53ba765c', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['45e5abb1-31d2-45a4-8ba2-564a9b4f0c89']}\n",
      "{'event': 'on_chain_stream', 'run_id': '45e5abb1-31d2-45a4-8ba2-564a9b4f0c89', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'chunk': '43214321'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '45e5abb1-31d2-45a4-8ba2-564a9b4f0c89', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "\n",
    "reverse_and_double = RunnableLambda(reverse_and_double)\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '26bff890-8682-4da7-93c3-6a0f84116c5d', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_word', 'tags': [], 'run_id': 'f459d024-d526-4ce0-9cb3-91f9ab3d19f7', 'metadata': {}, 'parent_ids': ['26bff890-8682-4da7-93c3-6a0f84116c5d']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '4321', 'input': '1234'}, 'run_id': 'f459d024-d526-4ce0-9cb3-91f9ab3d19f7', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['26bff890-8682-4da7-93c3-6a0f84116c5d']}\n",
      "{'event': 'on_chain_stream', 'run_id': '26bff890-8682-4da7-93c3-6a0f84116c5d', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'chunk': '43214321'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '26bff890-8682-4da7-93c3-6a0f84116c5d', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\"):\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
