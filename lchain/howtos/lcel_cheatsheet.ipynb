{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LangChain Expression Language Cheatsheet](https://python.langchain.com/docs/how_to/lcel_cheatsheet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoke a runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable = RunnableLambda(lambda x: str(x))\n",
    "runnable.invoke(5)\n",
    "\n",
    "# Async variant:\n",
    "# await runnable.ainvoke(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch a runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7', '8', '9']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable = RunnableLambda(lambda x: str(x))\n",
    "runnable.batch([7, 8, 9])\n",
    "\n",
    "# Async variant:\n",
    "# await runnable.abatch([7, 8, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stream a runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def func(x):\n",
    "    for y in x:\n",
    "        yield str(y)\n",
    "\n",
    "runnable = RunnableLambda(func)\n",
    "\n",
    "for chunk in runnable.stream(range(5)):\n",
    "    print(chunk)\n",
    "\n",
    "# Async variant:\n",
    "# async for chunk in await runnable.astream(range(5)):\n",
    "#     print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compose runnables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'foo': 2}, {'foo': 2}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 2)\n",
    "\n",
    "chain = runnable1 | runnable2\n",
    "\n",
    "chain.invoke(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invoke runnables in parallel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': {'foo': 2}, 'second': [2, 2]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 2)\n",
    "\n",
    "chain = RunnableParallel(first=runnable1, second=runnable2)\n",
    "\n",
    "chain.invoke(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn any function into a runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def func(x):\n",
    "    return x + 5\n",
    "\n",
    "runnable = RunnableLambda(func)\n",
    "runnable.invoke(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge input and output dicts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 10, 'bar': 17}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: x[\"foo\"] + 7)\n",
    "\n",
    "# In some cases, it may be useful to pass the input through while adding some keys to the output. \n",
    "# In this case, you can use the assign method\n",
    "chain = RunnablePassthrough.assign(bar=runnable1)\n",
    "\n",
    "chain.invoke({\"foo\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Include input dict in output dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bar': 17, 'baz': {'foo': 10}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: x[\"foo\"] + 7)\n",
    "\n",
    "chain = RunnableParallel(bar=runnable1, baz=RunnablePassthrough())\n",
    "\n",
    "chain.invoke({\"foo\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add default invocation args**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bar': 'hello', 'foo': 'bye'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def func(main_arg: dict, other_arg: Optional[str] = None) -> dict:\n",
    "    if other_arg:\n",
    "        return {**main_arg, **{\"foo\": other_arg}}\n",
    "    return main_arg\n",
    "\n",
    "\n",
    "runnable1 = RunnableLambda(func)\n",
    "bound_runnable1 = runnable1.bind(other_arg=\"bye\")\n",
    "\n",
    "bound_runnable1.invoke({\"bar\": \"hello\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add fallbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5foo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: x + \"foo\")\n",
    "runnable2 = RunnableLambda(lambda x: str(x) + \"foo\")\n",
    "\n",
    "chain = runnable1.with_fallbacks([runnable2])\n",
    "\n",
    "chain.invoke(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add retries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt with counter=0\n",
      "attempt with counter=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "counter = -1\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    global counter\n",
    "    counter += 1\n",
    "    print(f\"attempt with {counter=}\")\n",
    "    return x / counter\n",
    "\n",
    "\n",
    "chain = RunnableLambda(func).with_retry(stop_after_attempt=2)\n",
    "\n",
    "chain.invoke(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configure runnable execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': {'foo': 7}, 'second': [7, 7], 'third': '7'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 2)\n",
    "runnable3 = RunnableLambda(lambda x: str(x))\n",
    "\n",
    "chain = RunnableParallel(first=runnable1, second=runnable2, third=runnable3)\n",
    "\n",
    "chain.invoke(7, config={\"max_concurrency\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add default config to runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': {'foo': 7}, 'second': [7, 7], 'third': '7'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 2)\n",
    "runnable3 = RunnableLambda(lambda x: str(x))\n",
    "\n",
    "chain = RunnableParallel(first=runnable1, second=runnable2, third=runnable3)\n",
    "configured_chain = chain.with_config(max_concurrency=2)\n",
    "\n",
    "chain.invoke(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make runnable attributes configurable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not bar': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "from langchain_core.runnables import (\n",
    "    ConfigurableField,\n",
    "    RunnableConfig,\n",
    "    RunnableSerializable,\n",
    ")\n",
    "\n",
    "\n",
    "class FooRunnable(RunnableSerializable[dict, dict]):\n",
    "    output_key: str\n",
    "\n",
    "    def invoke(\n",
    "        self, input: Any, config: Optional[RunnableConfig] = None, **kwargs: Any\n",
    "    ) -> list:\n",
    "        return self._call_with_config(self.subtract_seven, input, config, **kwargs)\n",
    "\n",
    "    def subtract_seven(self, input: dict) -> dict:\n",
    "        return {self.output_key: input[\"foo\"] - 7}\n",
    "\n",
    "\n",
    "runnable1 = FooRunnable(output_key=\"bar\")\n",
    "configurable_runnable1 = runnable1.configurable_fields(\n",
    "    output_key=ConfigurableField(id=\"output_key\")\n",
    ")\n",
    "\n",
    "configurable_runnable1.invoke(\n",
    "    {\"foo\": 10}, config={\"configurable\": {\"output_key\": \"not bar\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make chain components configurable**\n",
    "\n",
    "例子没看太懂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'foo': 7}\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda, RunnableParallel\n",
    "\n",
    "\n",
    "class ListRunnable(RunnableSerializable[Any, list]):\n",
    "    def invoke(\n",
    "        self, input: Any, config: Optional[RunnableConfig] = None, **kwargs: Any\n",
    "    ) -> list:\n",
    "        return self._call_with_config(self.listify, input, config, **kwargs)\n",
    "\n",
    "    def listify(self, input: Any) -> list:\n",
    "        return [input]\n",
    "\n",
    "\n",
    "class StrRunnable(RunnableSerializable[Any, str]):\n",
    "    def invoke(\n",
    "        self, input: Any, config: Optional[RunnableConfig] = None, **kwargs: Any\n",
    "    ) -> list:\n",
    "        return self._call_with_config(self.strify, input, config, **kwargs)\n",
    "\n",
    "    def strify(self, input: Any) -> str:\n",
    "        return str(input)\n",
    "\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x})\n",
    "\n",
    "configurable_runnable = ListRunnable().configurable_alternatives(\n",
    "    ConfigurableField(id=\"second_step\"), default_key=\"list\", string=StrRunnable()\n",
    ")\n",
    "chain = runnable1 | configurable_runnable\n",
    "\n",
    "chain.invoke(7, config={\"configurable\": {\"second_step\": \"string\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'foo': 7}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a chain dynamically based on input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 7}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 2)\n",
    "\n",
    "chain = RunnableLambda(lambda x: runnable1 if x > 6 else runnable2)\n",
    "\n",
    "chain.invoke(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a stream of events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event=on_chain_start | name=RunnableSequence | data={'input': 'bar'}\n",
      "event=on_chain_start | name=first | data={}\n",
      "event=on_chain_stream | name=first | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_start | name=second | data={}\n",
      "event=on_chain_end | name=first | data={'output': {'foo': 'bar'}, 'input': 'bar'}\n",
      "event=on_chain_stream | name=second | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=RunnableSequence | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=second | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=RunnableSequence | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=second | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=RunnableSequence | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=second | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=RunnableSequence | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=second | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_stream | name=RunnableSequence | data={'chunk': {'foo': 'bar'}}\n",
      "event=on_chain_end | name=second | data={'output': {'foo': 'bar'}, 'input': {'foo': 'bar'}}\n",
      "event=on_chain_end | name=RunnableSequence | data={'output': {'foo': 'bar'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x}, name=\"first\")\n",
    "\n",
    "\n",
    "async def func(x):\n",
    "    for _ in range(5):\n",
    "        yield x\n",
    "\n",
    "\n",
    "runnable2 = RunnableLambda(func, name=\"second\")\n",
    "\n",
    "chain = runnable1 | runnable2\n",
    "\n",
    "async for event in chain.astream_events(\"bar\", version=\"v2\"):\n",
    "    print(f\"event={event['event']} | name={event['name']} | data={event['data']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yield batched outputs as they complete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slept 1\n",
      "1 None\n",
      "slept 5\n",
      "0 None\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: time.sleep(x) or print(f\"slept {x}\"))\n",
    "\n",
    "for idx, result in runnable1.batch_as_completed([5, 1]):\n",
    "    print(idx, result)\n",
    "\n",
    "# Async variant:\n",
    "# async for idx, result in runnable1.abatch_as_completed([5, 1]):\n",
    "#     print(idx, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Return subset of output dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 7, 'bar': 'hi'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: x[\"baz\"] + 5)\n",
    "chain = RunnablePassthrough.assign(foo=runnable1).pick([\"foo\", \"bar\"])\n",
    "\n",
    "chain.invoke({\"bar\": \"hi\", \"baz\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declaratively make a batched version of a runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: list(range(x)))\n",
    "runnable2 = RunnableLambda(lambda x: x + 5)\n",
    "\n",
    "chain = runnable1 | runnable2.map()\n",
    "\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a graph representation of a runnable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {\"foo\": x})\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 2)\n",
    "runnable3 = RunnableLambda(lambda x: str(x))\n",
    "\n",
    "chain = runnable1 | RunnableParallel(second=runnable2, third=runnable3)\n",
    "\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all prompts in a chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**prompt i=0**\n",
      "\n",
      "================================ System Message ================================\n",
      "\n",
      "good ai\n",
      "\n",
      "================================ Human Message =================================\n",
      "\n",
      "{input}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**prompt i=1**\n",
      "\n",
      "================================ System Message ================================\n",
      "\n",
      "really good ai\n",
      "\n",
      "================================ Human Message =================================\n",
      "\n",
      "{input}\n",
      "\n",
      "================================== AI Message ==================================\n",
      "\n",
      "{ai_output}\n",
      "\n",
      "================================ Human Message =================================\n",
      "\n",
      "{input2}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"good ai\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "prompt2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"really good ai\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{ai_output}\"),\n",
    "        (\"human\", \"{input2}\"),\n",
    "    ]\n",
    ")\n",
    "fake_llm = RunnableLambda(lambda prompt: \"i am good ai\")\n",
    "chain = prompt1.assign(ai_output=fake_llm) | prompt2 | fake_llm\n",
    "\n",
    "for i, prompt in enumerate(chain.get_prompts()):\n",
    "    print(f\"**prompt {i=}**\\n\")\n",
    "    print(prompt.pretty_repr())\n",
    "    print(\"\\n\" * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add lifecycle listeners**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time: 2025-03-02 12:40:41.071277+00:00\n",
      "end_time: 2025-03-02 12:40:43.075608+00:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tracers.schemas import Run\n",
    "\n",
    "\n",
    "def on_start(run_obj: Run):\n",
    "    print(\"start_time:\", run_obj.start_time)\n",
    "\n",
    "\n",
    "def on_end(run_obj: Run):\n",
    "    print(\"end_time:\", run_obj.end_time)\n",
    "\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: time.sleep(x))\n",
    "chain = runnable1.with_listeners(on_start=on_start, on_end=on_end)\n",
    "chain.invoke(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
