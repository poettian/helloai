{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先看一个 chain 的 stream 示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='Why' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' did' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' the' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' par' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='rot' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' wear' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' a' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' rain' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='coat' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='?\\n\\n' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='Because' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' it' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' wanted' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' to' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' be' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' a' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' poly' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='-uns' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='aturated' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content=' bird' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='!' additional_kwargs={} response_metadata={} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63'} id='run-df95c383-24bf-4900-b54a-d8eb2eb90372'|"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"parrot\"}):\n",
    "    print(chunk, end=\"|\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再来看一个对 stream json 的例子。\n",
    "\n",
    "langchain 里提到：the parser needs to operate on the input stream, and attempt to \"auto-complete\" the partial json into a valid state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 652}]}\n",
      "{'countries': [{'name': 'France', 'population': 652735}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 467547}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126476}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273511}, {'name': 'Spain', 'population': 46754778}, {'name': 'Japan', 'population': 126476461}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "chain = llm | parser\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    print(text, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any steps in the chain that operate on finalized inputs rather than on input streams can break streaming functionality via stream or astream.\n",
    "\n",
    "也就是说中间的组件必须具备处理 input stream 的能力，否则就会打断 stream。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "\n",
    "# A function that operates on finalized inputs\n",
    "# rather than on an input_stream\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = llm | parser | _extract_country_names\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以后续给了一个修正的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France|Spain|Japan|"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "    \"\"\"A function that operates on input streams.\"\"\"\n",
    "\n",
    "    country_names_so_far = set()\n",
    "\n",
    "    # 大模型里提到 input_stream 是一个异步迭代器\n",
    "    async for input in input_stream:\n",
    "        if not isinstance(input, dict):\n",
    "            continue\n",
    "\n",
    "        if \"countries\" not in input:\n",
    "            continue\n",
    "\n",
    "        countries = input[\"countries\"]\n",
    "\n",
    "        if not isinstance(countries, list):\n",
    "            continue\n",
    "\n",
    "        for country in countries:\n",
    "            name = country.get(\"name\")\n",
    "            if not name:\n",
    "                continue\n",
    "            if name not in country_names_so_far:\n",
    "                # 注意 yield 的用法\n",
    "                yield name\n",
    "                country_names_so_far.add(name)\n",
    "\n",
    "\n",
    "chain = llm | parser | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
