{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Build a Basic Chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "                         \n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "# Next, add an entry point. \n",
    "# This tells our graph where to start its work each time we run it.\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "# Similarly, set a finish point. \n",
    "# This instructs the graph \"any time this node is run, you can exit.\"\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi there! How can I help you today?\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Now let's run the chatbot!\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # Ê≥®ÊÑèÔºöËøôÈáå‰º†ÂÖ•ÁöÑ inputÔºåÂèØ‰ª•ËßÜ‰∏∫ State ÁöÑÂàùÂßãÂÄº\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: üõ†Ô∏è Enhancing the Chatbot with Tools**\n",
    "\n",
    "Êé•‰∏ãÊù•Â¢ûÂº∫ bot ËÉΩÂäõÔºåÈõÜÊàêËøõÊù•‰∏Ä‰∏™ web search tool„ÄÇ\n",
    "\n",
    "‰ΩøÁî® TavilyÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂõæÔºåÁúãÁùÄÊå∫Â•ΩÔºåÂèØ‰ª•ÂèÇËÄÉÔºàEmpower your chatbots to deliver precise, up-to-date responses by accessing a wide range of information through Tavily‚Äôs robust search capabilities.Ôºâ\n",
    "\n",
    "![Tavily Graph Example](https://tavily.com/_next/static/media/app-red-lg.25f93dc4.svg \"Tavily Graph Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U tavily-python langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "# tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x125f9d310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x125f9d310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools:list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict) -> dict:\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No messages found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "    \n",
    "tool_node = BasicToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(state: State):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\", \n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "# Because the condition can return END, we don't need to explicitly set a finish_point this time. Our graph already has a way to finish!\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: [{'text': 'ÊàëÂ∞ÜÂ∏ÆÊÇ®ÂØπÊØî LangGraph Âíå Dify Ëøô‰∏§‰∏™Â∑•ÂÖ∑„ÄÇËÆ©ÊàëÊêúÁ¥¢‰∏Ä‰∏ãÊúÄÊñ∞ÁöÑ‰ø°ÊÅØ„ÄÇ', 'type': 'text'}, {'id': 'toolu_01KLUY4DdjQNetCjHV8XczM2', 'input': {'query': 'LangGraph vs Dify AI development platforms comparison'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Assistant: [{\"url\": \"https://www.restack.io/p/dify-answer-vs-langgraph-cat-ai\", \"content\": \"Dify and LangGraph are both platforms designed to facilitate the development of applications utilizing large language models (LLMs), but they offer distinct features that cater to different user needs. docs.dify.ai docs.dify.ai/guides/monitoring/integrate-external-ops-tools/integrate-langsmith docs.dify.ai docs.dify.ai/guides/application-publishing/developing-with-apis docs.dify.ai docs.dify.ai/learn-more/extended-reading/what-is-llmops Dify provides a robust API that allows developers to integrate large language model (LLM) capabilities into their applications seamlessly. Secure Access: Dify enables frontend applications to access LLM capabilities without the need for extensive backend development, ensuring a secure environment for users. By utilizing the detailed logs available in LangGraph, developers can enhance the performance of their Dify applications effectively. Dify Open Source Overview Explore Dify's open source capabilities, features, and community contributions for enhanced development.\"}, {\"url\": \"https://www.restack.io/p/dify-answer-n8n-vs-langgraph-cat-ai\", \"content\": \"Explore the technical differences between n8n and Langgraph in the context of Dify's capabilities. Dify Vs N8N Comparison Explore the differences between Dify and N8N, focusing on their features, integrations, and use cases for automation. With the integration of LangGraph and Dify, developers can significantly enhance their LLMOps capabilities, streamlining the development and management of LLM-based applications. Ease of Use: Dify's user-friendly interface allows for seamless collaboration among team members, whereas n8n may require more technical knowledge to set up workflows effectively. While n8n and LangGraph have their strengths, particularly in workflow automation and data management, Dify's focus on simplifying the development process and enhancing collaboration makes it a compelling choice for teams looking to leverage LLM technology effectively.\"}]\n",
      "Assistant: [{'id': 'toolu_01NoeqvCcKvSD1Emz1YjHfuo', 'input': {'query': 'LangGraph and Dify key features for AI application development'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Assistant: [{\"url\": \"https://www.restack.io/p/dify-answer-vs-langgraph-cat-ai\", \"content\": \"Dify and LangGraph are both platforms designed to facilitate the development of applications utilizing large language models (LLMs), but they offer distinct features that cater to different user needs. docs.dify.ai docs.dify.ai/guides/monitoring/integrate-external-ops-tools/integrate-langsmith docs.dify.ai docs.dify.ai/guides/application-publishing/developing-with-apis docs.dify.ai docs.dify.ai/learn-more/extended-reading/what-is-llmops Dify provides a robust API that allows developers to integrate large language model (LLM) capabilities into their applications seamlessly. Secure Access: Dify enables frontend applications to access LLM capabilities without the need for extensive backend development, ensuring a secure environment for users. By utilizing the detailed logs available in LangGraph, developers can enhance the performance of their Dify applications effectively. Dify Open Source Overview Explore Dify's open source capabilities, features, and community contributions for enhanced development.\"}, {\"url\": \"https://medium.com/@researchgraph/getting-started-with-dify-no-code-ai-application-development-52c98aef48f7\", \"content\": \"Getting Started with Dify: No-Code AI Application Development | by Research Graph | Medium Getting Started with Dify: No-Code AI Application Development Dify is an open-source large language model (LLM) application development platform. It combines the concepts of Backend-as-a-Service and LLMOps to enable developers to quickly build production-grade generative AI applications. By integrating the key technology stacks required for building LLM applications, including support for hundreds of models, an intuitive Prompt orchestration interface, high-quality RAG engines, and a flexible Agent framework, while providing a set of easy-to-use interfaces and APIs, Dify saves developers a lot of time reinventing the wheel, allowing them to focus on innovation and business needs. The name Dify comes from Define + Modify, referring to defining and continuously improving your AI applications. Follow Follow\"}]\n",
      "Assistant: Ê†πÊçÆÊêúÁ¥¢ÁªìÊûúÔºåÊàëÂèØ‰ª•‰∏∫ÊÇ®ËØ¶ÁªÜÂØπÊØî LangGraph Âíå DifyÔºö\n",
      "\n",
      "1. ÂÆö‰ΩçÂíåÁõÆÊ†á\n",
      "- LangGraphÔºö‰∏ìÊ≥®‰∫éÂ§çÊùÇÁöÑ LLM Â∑•‰ΩúÊµÅÂíåÂõæÁä∂ÊÄÅÁÆ°ÁêÜ\n",
      "- DifyÔºöÈù¢ÂêëÊõ¥ÂπøÊ≥õÁöÑ AI Â∫îÁî®ÂºÄÂèëÔºåÊèê‰æõÊó†‰ª£Á†Å/‰Ωé‰ª£Á†ÅÁöÑÂºÄÂèëÊñπÂºè\n",
      "\n",
      "2. ÂäüËÉΩÁâπÁÇπ\n",
      "Dify ÁâπÁÇπÔºö\n",
      "- ÂºÄÊ∫êÂπ≥Âè∞\n",
      "- Êèê‰æõÊó†‰ª£Á†Å AI Â∫îÁî®ÂºÄÂèë\n",
      "- ÊîØÊåÅÂ§öÁßçÊ®°ÂûãÔºàÊï∞Áôæ‰∏™Ê®°ÂûãÔºâ\n",
      "- ÂÜÖÁΩÆ Prompt ÁºñÊéíÁïåÈù¢\n",
      "- È´òË¥®ÈáèÁöÑ RAGÔºàÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºâÂºïÊìé\n",
      "- ÁÅµÊ¥ªÁöÑ Agent Ê°ÜÊû∂\n",
      "- Êèê‰æõÁÆÄÂçïÊòìÁî®ÁöÑÊé•Âè£Âíå API\n",
      "\n",
      "LangGraph ÁâπÁÇπÔºö\n",
      "- ‰∏ìÊ≥®‰∫éÂ§çÊùÇÁöÑÁä∂ÊÄÅÁÆ°ÁêÜÂíåÂ∑•‰ΩúÊµÅÁºñÊéí\n",
      "- Êõ¥ÂÅèÂêë‰∫éÊäÄÊúØÂºÄÂèëËÄÖ\n",
      "- Êèê‰æõËØ¶ÁªÜÁöÑÊó•ÂøóÂíåÊÄßËÉΩËøΩË∏™\n",
      "- ÈÄÇÂêàÊûÑÂª∫Â§çÊùÇÁöÑÂ§öÊ≠•È™§ AI Â∑•‰ΩúÊµÅ\n",
      "\n",
      "3. ‰ΩøÁî®ÈöæÂ∫¶\n",
      "- DifyÔºöÊõ¥Âä†Áî®Êà∑ÂèãÂ•ΩÔºåÈÄÇÂêàÊ≤°ÊúâÊ∑±Â∫¶ÊäÄÊúØËÉåÊôØÁöÑÂºÄÂèëËÄÖ\n",
      "- LangGraphÔºöÈúÄË¶ÅÊõ¥Â§öÊäÄÊúØÁü•ËØÜÔºåÊõ¥ÈÄÇÂêàÊúâÁªèÈ™åÁöÑÂºÄÂèëËÄÖ\n",
      "\n",
      "4. Â∫îÁî®Âú∫ÊôØ\n",
      "Dify ÈÄÇÂêàÔºö\n",
      "- Âø´ÈÄüÊûÑÂª∫Áîü‰∫ßÁ∫ß AI Â∫îÁî®\n",
      "- ÈúÄË¶ÅÁÆÄÂçïÈõÜÊàê LLM ËÉΩÂäõÁöÑÈ°πÁõÆ\n",
      "- Âõ¢ÈòüÂçè‰ΩúÂºÄÂèë\n",
      "\n",
      "LangGraph ÈÄÇÂêàÔºö\n",
      "- Â§çÊùÇÁöÑ AI Â∑•‰ΩúÊµÅÁ®ãËÆæËÆ°\n",
      "- ÈúÄË¶ÅÁ≤æÁªÜÁä∂ÊÄÅÁÆ°ÁêÜÁöÑÈ°πÁõÆ\n",
      "- È´òÂ∫¶ÂÆöÂà∂ÂåñÁöÑ AI Â∫îÁî®ÂºÄÂèë\n",
      "\n",
      "5. ÂºÄÊ∫êÊÉÖÂÜµ\n",
      "- DifyÔºöÂÆåÂÖ®ÂºÄÊ∫ê\n",
      "- LangGraphÔºö‰πüÊòØÂºÄÊ∫êÈ°πÁõÆÔºåÁî± LangChain Âõ¢ÈòüÁª¥Êä§\n",
      "\n",
      "6. ‰ºòÂäø‰∫íË°•\n",
      "ÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËøô‰∏§‰∏™Â∑•ÂÖ∑Âπ∂ÈùûÂÆåÂÖ®Á´û‰∫âÂÖ≥Á≥ªÔºåÂÆûÈôÖ‰∏äÂèØ‰ª•‰∫íÁõ∏Ë°•ÂÖÖ„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Âú® Dify ‰∏≠Âà©Áî® LangGraph ÁöÑÊó•ÂøóÊù•‰ºòÂåñÂ∫îÁî®ÊÄßËÉΩ„ÄÇ\n",
      "\n",
      "ÈÄâÊã©Âª∫ËÆÆÔºö\n",
      "- Â¶ÇÊûú‰Ω†ÊòØÂàùÂ≠¶ËÄÖÊàñÈúÄË¶ÅÂø´ÈÄüÊûÑÂª∫ AI Â∫îÁî®ÔºåÈÄâÊã© Dify\n",
      "- Â¶ÇÊûú‰Ω†ÊòØÈ´òÁ∫ßÂºÄÂèëËÄÖÔºåÈúÄË¶ÅÂ§çÊùÇÁöÑÂ∑•‰ΩúÊµÅÁºñÊéíÔºåÂèØ‰ª•ÈÄâÊã© LangGraph\n",
      "- ÂØπ‰∫éÂ§çÊùÇÈ°πÁõÆÔºåÂèØ‰ª•ËÄÉËôë‰∏§ËÄÖÁªìÂêà‰ΩøÁî®\n",
      "\n",
      "ÊÄªÁöÑÊù•ËØ¥ÔºåDify Êõ¥ÂÉèÊòØ‰∏ÄÁ´ôÂºèÁöÑ AI Â∫îÁî®ÂºÄÂèëÂπ≥Âè∞ÔºåËÄå LangGraph Êõ¥‰∏ìÊ≥®‰∫éÂ∑•‰ΩúÊµÅÁöÑÁ≤æÁªÜÊéßÂà∂„ÄÇ\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Now let's run the chatbot!\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Question: langgraph Âíå dify ÂØπÊØî\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langGraph Êèê‰æõ‰∫Ü‰∏Ä‰∏™ÁÆÄÂåñÁöÑÁâàÊú¨Ôºå‰ΩøÁî® `ToolNode` ÊõøÊç¢ `BasicToolNode`Ôºå‰ΩøÁî® `tools_condition` ÊõøÊç¢ `route_tools`„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3: Adding Memory to the Chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Tian Zhiwei.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Tian Zhiwei! It's nice to meet you. How are you doing today? Is there anything I can help you with?\n"
     ]
    }
   ],
   "source": [
    "# First, pick a thread to use as the key for this conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = \"Hi there! My name is Tian Zhiwei.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, I will remember your name as Tian Zhiwei. I appreciate you introducing yourself. Is there something specific I can assist you with today?\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÜÖÂ≠òËÆ∞ÂøÜÂøÖÈ°ªÊòØËøêË°åÂú®Âêå‰∏Ä‰∏™ËøõÁ®ã‰∏≠ÊâçÂèØ‰ª•„ÄÇËØïÈ™å‰∫Ü‰∏ãÔºåÂç≥‰Ωø‰ΩøÁî®Âêå‰∏Ä‰∏™ thread_idÔºåÂú®ÂëΩ‰ª§Ë°å‰∏§Ê¨°ÊâßË°å `python test.py` Â∞±Êó†Ê≥ïÂÆûÁé∞ËÆ∞ÂøÜËÉΩÂäõ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I apologize, but I do not have any prior context to remember your name. Each conversation starts fresh, and I do not have the ability to retain information from previous interactions. If you'd like, you can simply tell me your name in this conversation, and I'll be happy to address you by it during our chat.\n"
     ]
    }
   ],
   "source": [
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Tian Zhiwei.', additional_kwargs={}, response_metadata={}, id='bae8e4cd-1571-479a-b8a6-51800aefe34d'), AIMessage(content=\"Hello Tian Zhiwei! It's nice to meet you. How are you doing today? Is there anything I can help you with?\", additional_kwargs={}, response_metadata={'id': 'msg_01AttrpCogPfQycLgeHakovL', 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 381, 'output_tokens': 34}}, id='run-456967db-321e-46a7-b5ad-c49af2538120-0', usage_metadata={'input_tokens': 381, 'output_tokens': 34, 'total_tokens': 415, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), HumanMessage(content='Remember my name?', additional_kwargs={}, response_metadata={}, id='e7193579-33ae-45d7-aee3-bbb8cfe9bef4'), AIMessage(content='Yes, I will remember your name as Tian Zhiwei. I appreciate you introducing yourself. Is there something specific I can assist you with today?', additional_kwargs={}, response_metadata={'id': 'msg_01Qk9oSoCnVaFUtFJnHj3N8u', 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 422, 'output_tokens': 36}}, id='run-ee31fb08-8750-47d6-b6e7-56f527f0bf6b-0', usage_metadata={'input_tokens': 422, 'output_tokens': 36, 'total_tokens': 458, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efe92a1-ac07-6ffa-8004-8563e20bc10d'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='Yes, I will remember your name as Tian Zhiwei. I appreciate you introducing yourself. Is there something specific I can assist you with today?', additional_kwargs={}, response_metadata={'id': 'msg_01Qk9oSoCnVaFUtFJnHj3N8u', 'model': 'claude-3-5-haiku-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 422, 'output_tokens': 36}}, id='run-ee31fb08-8750-47d6-b6e7-56f527f0bf6b-0', usage_metadata={'input_tokens': 422, 'output_tokens': 36, 'total_tokens': 458, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}}, 'thread_id': '1', 'step': 4, 'parents': {}}, created_at='2025-02-12T10:14:11.849606+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efe92a1-99c1-659e-8003-daa89485cbb7'}}, tasks=())"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆåÊï¥ÁöÑ‰ª£Á†ÅÁ§∫‰æãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4: Human-in-the-loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x126713020>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building an AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you request human assistance for guidance on building an AI agent.\", 'type': 'text'}, {'id': 'toolu_016JGKPzKFQTEjU3rohQaiHi', 'input': {'query': \"I'm looking for expert guidance on building an AI agent. Could you provide advice on the key considerations, best practices, and potential challenges in designing and implementing an effective AI agent? I'm interested in understanding the technical architecture, development process, and important factors to consider for creating a robust and intelligent agent.\"}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_016JGKPzKFQTEjU3rohQaiHi)\n",
      " Call ID: toolu_016JGKPzKFQTEjU3rohQaiHi\n",
      "  Args:\n",
      "    query: I'm looking for expert guidance on building an AI agent. Could you provide advice on the key considerations, best practices, and potential challenges in designing and implementing an effective AI agent? I'm interested in understanding the technical architecture, development process, and important factors to consider for creating a robust and intelligent agent.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â§ßÊ®°ÂûãÁ°ÆÂÆûÁªôÂá∫‰∫Ü ‚Äúhuman_assistance‚Äù Ëøô‰∏™ tool ÁöÑË∞ÉÁî®Ôºå‰ΩÜÊòØÂú®ÊâßË°å tool Êó∂ÔºåË¢´‰∏≠Êñ≠‰∫ÜÔºåËøô‰∏™Ë≤å‰ººÊòØÈ¢ÑÊúüÂÜÖÁöÑÔºü‰ΩÜÊòØÊ≤°ÊúâÂá∫Áé∞ÈúÄË¶Å‰∫∫Â∑•‰ªãÂÖ•ÁöÑÂú∞ÊñπÔºåhuman_response ‰πüÊ≤°ÊúâËøîÂõûÂÄºÔºå‰ªé langSmith ‰∏äÁúãÊòØÊúâÊä•ÈîôÁöÑÔºöGraphInterrupt„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you request human assistance for guidance on building an AI agent.\", 'type': 'text'}, {'id': 'toolu_016JGKPzKFQTEjU3rohQaiHi', 'input': {'query': \"I'm looking for expert guidance on building an AI agent. Could you provide advice on the key considerations, best practices, and potential challenges in designing and implementing an effective AI agent? I'm interested in understanding the technical architecture, development process, and important factors to consider for creating a robust and intelligent agent.\"}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_016JGKPzKFQTEjU3rohQaiHi)\n",
      " Call ID: toolu_016JGKPzKFQTEjU3rohQaiHi\n",
      "  Args:\n",
      "    query: I'm looking for expert guidance on building an AI agent. Could you provide advice on the key considerations, best practices, and potential challenges in designing and implementing an effective AI agent? I'm interested in understanding the technical architecture, development process, and important factors to consider for creating a robust and intelligent agent.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the expert advice, I can elaborate a bit more:\n",
      "\n",
      "The expert suggests using LangGraph for building your AI agent, which is a library that provides more reliability and extensibility compared to traditional autonomous agent approaches. LangGraph is particularly useful for creating complex, stateful AI agents with more predictable and controllable behavior.\n",
      "\n",
      "Key recommendations for building an AI agent:\n",
      "1. Use LangGraph as your development framework\n",
      "2. Focus on creating a robust and flexible architecture\n",
      "3. Consider the agent's state management and interaction flow\n",
      "4. Ensure extensibility for future improvements\n",
      "\n",
      "Would you like me to help you find more detailed information about LangGraph or AI agent development? I can search for some additional resources and best practices to support your project.\n"
     ]
    }
   ],
   "source": [
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆåÊï¥ÁöÑ‰ª£Á†ÅÁ§∫‰æãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 5: Customizing State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\n",
    "        \"question\": \"Is this correct?\",\n",
    "        \"name\": name,\n",
    "        \"birthday\": birthday,\n",
    "    })\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "    \n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "thread_id = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll search for information about when LangGraph was released.\", 'type': 'text'}, {'id': 'toolu_011uxfbdRyh31kGxGLEnGGVt', 'input': {'query': 'LangGraph release date launch'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_011uxfbdRyh31kGxGLEnGGVt)\n",
      " Call ID: toolu_011uxfbdRyh31kGxGLEnGGVt\n",
      "  Args:\n",
      "    query: LangGraph release date launch\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://pypi.org/project/langgraph/\", \"content\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The simplest way to create a tool-calling agent in LangGraph is to use create_react_agent: # Define the tools for the agent to use # Define the tools for the agent to use # This means that after `tools` is called, `agent` node is called next. workflow.add_edge(\\\"tools\\\", 'agent') Normal edge: after the tools are invoked, the graph should always return to the agent to decide what to do next LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, \\\"agent\\\". langgraph-0.2.70-py3-none-any.whl (149.7 kB view details)Uploaded Feb 6, 2025 Python 3\"}, {\"url\": \"https://changelog.langchain.com/?date=2024-01-01\", \"content\": \"LangChain - Changelog LangChain LangSmith LangGraph Blog Case Studies LangChain Academy Community Experts Changelog LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain Changelog This splits up the previous langchain package into three different... LangChain üöÄ OpenGPTs ----------- After OpenAI‚Äôs DevDay, we launched a project inspired by GPTs and the Assistants API. LangChain üìä LangChain Benchmarks for Python ---------------------------------- LangChain benchmarks is a Python package with associated datasets to facilitate experimentation and benchmarking of different cognitive architectures. LangSmith SaaS ‚úçÔ∏è Data Annotation Queues in LangSmith -------------------------------------- We've launched our newest feature, data annotation queues, in LangSmith (our SaaS platform for managing your LangChain applications). Subscribe By clicking subscribe, you accept our privacy policy and terms and conditions.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll do another search to confirm the release date:\", 'type': 'text'}, {'id': 'toolu_013z14Fu995vW9JvLXsxjPH4', 'input': {'query': 'LangGraph official release date by LangChain'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_013z14Fu995vW9JvLXsxjPH4)\n",
      " Call ID: toolu_013z14Fu995vW9JvLXsxjPH4\n",
      "  Args:\n",
      "    query: LangGraph official release date by LangChain\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"content\": \"Releases ¬∑ langchain-ai/langgraph ¬∑ GitHub Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases ¬∑ langchain-ai/langgraph langgraph: release 0.2.70 (#3341) langgraph: add agent name to AI messages in create_react_agent (#3340) fix(langgraph): Dedupe input (right-side) messages in add_messages (#3338) Merge branch 'jacob/dedupe' of github.com:langchain-ai/langgraph into jacob/dedupe langgraph: release 0.2.69 (#3256) docs: update README to include built w/ langgraph (#3254) langgraph: add get_stream_writer() (#3251) langgraph: release 0.2.68 (#3224) langgraph: actually fix flaky test (#3219) langgraph: use 'prompt' param for model input preprocessing in create_react_agent (#3173) langgraph: fix flaky test (#3218) langgraph: add names for tasks (#3202) langgraph: update docstrings/api ref for functional api (#3176) langgraph: add support for BaseModel updates to Command (#2747) langgraph: allow async state modifier in create_react_agent (#3161)\"}, {\"url\": \"https://changelog.langchain.com/?date=2024-01-01\", \"content\": \"LangChain - Changelog LangChain LangSmith LangGraph Blog Case Studies LangChain Academy Community Experts Changelog LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain Changelog This splits up the previous langchain package into three different... LangChain üöÄ OpenGPTs ----------- After OpenAI‚Äôs DevDay, we launched a project inspired by GPTs and the Assistants API. LangChain üìä LangChain Benchmarks for Python ---------------------------------- LangChain benchmarks is a Python package with associated datasets to facilitate experimentation and benchmarking of different cognitive architectures. LangSmith SaaS ‚úçÔ∏è Data Annotation Queues in LangSmith -------------------------------------- We've launched our newest feature, data annotation queues, in LangSmith (our SaaS platform for managing your LangChain applications). Subscribe By clicking subscribe, you accept our privacy policy and terms and conditions.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Based on the search results, it appears that LangGraph was released relatively recently, with versions like 0.2.70 being uploaded in early 2024. However, to ensure I have the most accurate information, I'll use the human assistance tool:\", 'type': 'text'}, {'id': 'toolu_01URpCvDhDms9UL2s32sTUpF', 'input': {'name': 'LangGraph Release Date', 'birthday': '2024-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01URpCvDhDms9UL2s32sTUpF)\n",
      " Call ID: toolu_01URpCvDhDms9UL2s32sTUpF\n",
      "  Args:\n",
      "    name: LangGraph Release Date\n",
      "    birthday: 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Based on the search results, it appears that LangGraph was released relatively recently, with versions like 0.2.70 being uploaded in early 2024. However, to ensure I have the most accurate information, I'll use the human assistance tool:\", 'type': 'text'}, {'id': 'toolu_01URpCvDhDms9UL2s32sTUpF', 'input': {'name': 'LangGraph Release Date', 'birthday': '2024-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_01URpCvDhDms9UL2s32sTUpF)\n",
      " Call ID: toolu_01URpCvDhDms9UL2s32sTUpF\n",
      "  Args:\n",
      "    name: LangGraph Release Date\n",
      "    birthday: 2024-01-01\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the human assistance verification, LangGraph was officially released on January 17, 2024. This aligns with the version history and changelog information I found in the search results, which showed early 2024 releases of the library by LangChain.\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langGraph ÊèêÂà∞ÔºöÂú®‰ªª‰ΩïËäÇÁÇπÂåÖÊã¨ interrupted Êó∂ÔºåÈÉΩÂèØ‰ª•‰øÆÊîπ state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': UUID('33c10ff4-5027-40ff-b52b-6e7d9ab30077'),\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efe9e53-977d-65cc-8008-48511356f74a'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÂÆåÊï¥ÁöÑ‰ª£Á†ÅÂ¶Ç‰∏ãÔºö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    return Command(update=state_update)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 6: Time Travel**\n",
    "\n",
    "ËÉΩÂ§üÂõûÊí§Âà∞‰πãÂâçÁöÑÊüê‰∏™ËäÇÁÇπÔºåÈáçÊñ∞ÂØπËØù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "thread_id = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll search for information about LangGraph to help you learn more about it.\", 'type': 'text'}, {'id': 'toolu_01CqytMS75eAhWNnCu51Vfmf', 'input': {'query': 'LangGraph AI library LangChain what is it used for'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01CqytMS75eAhWNnCu51Vfmf)\n",
      " Call ID: toolu_01CqytMS75eAhWNnCu51Vfmf\n",
      "  Args:\n",
      "    query: LangGraph AI library LangChain what is it used for\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\"}, {\"url\": \"https://www.getzep.com/ai-agents/langchain-agents-langgraph\", \"content\": \"LangGraph handles complex workflows through graph-based orchestration, persistent state management, and multi-agent coordination, making it better suited for advanced applications. | LangGraph features | Supports graph-based workflows for dynamic decision-making, cyclical graphs for iterative processes, persistent state management, and integration with LangChain and LangSmith for monitoring and optimization. Building a single-agent workflow in LangGraph is straightforward and demonstrates the core concepts of the framework, such as state management and graph-based workflows. CHAPTER 2 LangGraph Tutorial: Building Agents with LangChain's Agent Framework Learn how LangGraph, an AI agent framework built by LangChain, allows developers to create complex and flexible agent workflows using stateful graphs and built-in memory management.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results, here's a comprehensive overview of LangGraph:\n",
      "\n",
      "LangGraph is a powerful library within the LangChain ecosystem designed to help developers create and manage complex AI agent workflows. Here are its key features and characteristics:\n",
      "\n",
      "1. Purpose:\n",
      "- Provides a framework for defining, coordinating, and executing multiple LLM (Large Language Model) agents\n",
      "- Enables the creation of sophisticated multi-agent systems and complex AI applications\n",
      "\n",
      "2. Key Capabilities:\n",
      "- Graph-based orchestration of AI workflows\n",
      "- Persistent state management\n",
      "- Dynamic decision-making support\n",
      "- Cyclical graph support for iterative processes\n",
      "- Simplified coordination of agent interactions\n",
      "\n",
      "3. Main Benefits:\n",
      "- Allows developers to focus on high-level application logic\n",
      "- Simplifies the development of complex LLM applications\n",
      "- Supports building advanced systems like multi-agent chatbots\n",
      "- Provides structured framework for managing agent states and interactions\n",
      "\n",
      "4. Technical Highlights:\n",
      "- Integrates with LangChain and LangSmith\n",
      "- Supports building both single and multi-agent workflows\n",
      "- Offers built-in memory management\n",
      "- Enables creation of dynamic and flexible AI agent systems\n",
      "\n",
      "Use cases include building sophisticated chatbots, complex task-solving agents, and interactive AI applications that require nuanced, multi-step reasoning and coordination.\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of LangGraph or explain how it might be used in a practical scenario?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "             {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":\"you should use tavily_search_results_json tool just once\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'Let me search for some guidance on building an autonomous agent with LangGraph to provide you with some practical insights.', 'type': 'text'}, {'id': 'toolu_01Jht3mbENSCgtN44mBMQUu7', 'input': {'query': 'How to build autonomous agent with LangGraph example tutorial'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01Jht3mbENSCgtN44mBMQUu7)\n",
      " Call ID: toolu_01Jht3mbENSCgtN44mBMQUu7\n",
      "  Args:\n",
      "    query: How to build autonomous agent with LangGraph example tutorial\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832\", \"content\": \"In this step, we‚Äôll define how the AI agent manages its state (the ongoing context of the conversation) and ensure it responds appropriately to the user‚Äôs input and tool output. This involves creating a template for the conversation, specifying the tools that the assistant will use, and configuring how the AI agent will respond to user input and trigger different functions (like calculating solar savings). This step ensures that the AI assistant can access and trigger the tools as needed during the conversation, creating a seamless interaction between the user and the assistant. By following these steps, you have successfully created an AI assistant using LangGraph that can calculate solar panel energy savings based on user inputs.\"}, {\"url\": \"https://www.youtube.com/watch?v=assrhPxNdSk\", \"content\": \"In this tutorial, we'll break down the fundamentals of building AI agents using LangGraph! Whether you're new to AI development or looking\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! Here are some key steps and considerations for building an autonomous agent with LangGraph:\n",
      "\n",
      "1. Agent Design Principles:\n",
      "- Define the agent's state management\n",
      "- Specify the tools and functions the agent can use\n",
      "- Create a conversation template\n",
      "- Configure how the agent responds to inputs and triggers actions\n",
      "\n",
      "2. Key Components to Consider:\n",
      "- State tracking\n",
      "- Tool integration\n",
      "- Decision-making logic\n",
      "- Interaction flow\n",
      "- Context management\n",
      "\n",
      "3. Typical Development Process:\n",
      "- Choose your specific use case\n",
      "- Select appropriate tools/APIs\n",
      "- Define agent's capabilities\n",
      "- Create a workflow graph\n",
      "- Implement state management\n",
      "- Test and iterate\n",
      "\n",
      "Practical Tips:\n",
      "- Start with a simple use case\n",
      "- Use LangChain's tool integrations\n",
      "- Leverage persistent state management\n",
      "- Implement clear decision-making rules\n",
      "\n",
      "Some potential autonomous agent ideas:\n",
      "- Research assistant\n",
      "- Personal productivity agent\n",
      "- Technical troubleshooting bot\n",
      "- Data analysis assistant\n",
      "- Customer support agent\n",
      "\n",
      "Would you like me to elaborate on any of these points or discuss a specific type of autonomous agent you're interested in building?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  9 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  8 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 8:\n",
    "        # We are somewhat arbitrarily selecting a specific state \n",
    "        # based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chatbot',)\n",
      "{'configurable': {'thread_id': UUID('676a9a98-1ced-46fd-a216-5594f5ac7d6f'), 'checkpoint_ns': '', 'checkpoint_id': '1efe9fce-7de4-674c-8007-ecaf17df8fb3'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832\", \"content\": \"In this step, we‚Äôll define how the AI agent manages its state (the ongoing context of the conversation) and ensure it responds appropriately to the user‚Äôs input and tool output. This involves creating a template for the conversation, specifying the tools that the assistant will use, and configuring how the AI agent will respond to user input and trigger different functions (like calculating solar savings). This step ensures that the AI assistant can access and trigger the tools as needed during the conversation, creating a seamless interaction between the user and the assistant. By following these steps, you have successfully created an AI assistant using LangGraph that can calculate solar panel energy savings based on user inputs.\"}, {\"url\": \"https://www.youtube.com/watch?v=assrhPxNdSk\", \"content\": \"In this tutorial, we'll break down the fundamentals of building AI agents using LangGraph! Whether you're new to AI development or looking\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! Building an autonomous agent with LangGraph involves several key steps:\n",
      "\n",
      "1. Define the Agent's State\n",
      "- Create a context template for the conversation\n",
      "- Specify the tools the agent will use\n",
      "- Configure how the agent responds to inputs and triggers functions\n",
      "\n",
      "2. Key Components to Consider:\n",
      "- State management\n",
      "- Tool integration\n",
      "- Decision-making logic\n",
      "- Conversation flow\n",
      "\n",
      "3. Basic Development Process:\n",
      "- Choose the agent's purpose\n",
      "- Select appropriate tools\n",
      "- Design the agent's workflow\n",
      "- Implement state and context handling\n",
      "- Test and refine the agent's interactions\n",
      "\n",
      "Practical Tips:\n",
      "- Start with a clear, specific goal for your autonomous agent\n",
      "- Begin with a simple use case and gradually add complexity\n",
      "- Leverage LangGraph's built-in state management\n",
      "- Use LangChain tools to extend your agent's capabilities\n",
      "\n",
      "Would you like me to elaborate on any of these points or discuss a specific type of autonomous agent you're interested in creating? I can provide more detailed guidance on the implementation process.\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
